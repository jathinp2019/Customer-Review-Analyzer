{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of test data =  (119606, 17)\n",
            "Shape of train data =  (478421, 18)\n",
            "\n",
            "\n",
            "Train Data Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 478421 entries, 0 to 478420\n",
            "Data columns (total 18 columns):\n",
            " #   Column                        Non-Null Count   Dtype \n",
            "---  ------                        --------------   ----- \n",
            " 0   Date received                 478421 non-null  object\n",
            " 1   Product                       478421 non-null  object\n",
            " 2   Sub-product                   339948 non-null  object\n",
            " 3   Issue                         478421 non-null  object\n",
            " 4   Sub-issue                     185796 non-null  object\n",
            " 5   Consumer complaint narrative  75094 non-null   object\n",
            " 6   Company public response       90392 non-null   object\n",
            " 7   Company                       478421 non-null  object\n",
            " 8   State                         474582 non-null  object\n",
            " 9   ZIP code                      474573 non-null  object\n",
            " 10  Tags                          67206 non-null   object\n",
            " 11  Consumer consent provided?    135487 non-null  object\n",
            " 12  Submitted via                 478421 non-null  object\n",
            " 13  Date sent to company          478421 non-null  object\n",
            " 14  Company response to consumer  478421 non-null  object\n",
            " 15  Timely response?              478421 non-null  object\n",
            " 16  Consumer disputed?            478421 non-null  object\n",
            " 17  Complaint ID                  478421 non-null  int64 \n",
            "dtypes: int64(1), object(17)\n",
            "memory usage: 65.7+ MB\n",
            "None\n",
            "\n",
            "\n",
            "The percentage of null data in the train dataset:\n",
            "Date received                    0.000000\n",
            "Product                          0.000000\n",
            "Sub-product                     28.943755\n",
            "Issue                            0.000000\n",
            "Sub-issue                       61.164748\n",
            "Consumer complaint narrative    84.303783\n",
            "Company public response         81.106181\n",
            "Company                          0.000000\n",
            "State                            0.802431\n",
            "ZIP code                         0.804313\n",
            "Tags                            85.952540\n",
            "Consumer consent provided?      71.680382\n",
            "Submitted via                    0.000000\n",
            "Date sent to company             0.000000\n",
            "Company response to consumer     0.000000\n",
            "Timely response?                 0.000000\n",
            "Consumer disputed?               0.000000\n",
            "Complaint ID                     0.000000\n",
            "dtype: float64\n",
            "Product : train: 12  test: 12\n",
            "Sub-product : train: 47  test: 47\n",
            "Issue : train: 95  test: 94\n",
            "Sub-issue : train: 68  test: 67\n",
            "Consumer complaint narrative : train: 74019  test: 18438\n",
            "Company public response : train: 10  test: 10\n",
            "Company : train: 3276  test: 2237\n",
            "State : train: 62  test: 62\n",
            "ZIP code : train: 25962  test: 17784\n",
            "Tags : train: 3  test: 3\n",
            "Consumer consent provided? : train: 4  test: 4\n",
            "Submitted via : train: 6  test: 6\n",
            "Company response to consumer : train: 7  test: 7\n",
            "Timely response? : train: 2  test: 2\n"
          ]
        }
      ],
      "source": [
        "#Header\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from category_encoders.one_hot import OneHotEncoder\n",
        "from category_encoders.ordinal import OrdinalEncoder\n",
        "from category_encoders.binary import BinaryEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "\n",
        "#Importing the datasets\n",
        "test_data = pd.read_csv('D:\\Jathin\\jathin\\jathin\\ML Project\\P1 Data\\Consumer_Complaints_test_share.csv')\n",
        "train_data = pd.read_csv('D:\\Jathin\\jathin\\jathin\\ML Project\\P1 Data\\Consumer_Complaints_train.csv')\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "\n",
        "test_shape = test_data.shape\n",
        "train_shape = train_data.shape\n",
        "print(\"Shape of test data = \", test_shape)\n",
        "print(\"Shape of train data = \", train_shape)\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"Train Data Information:\")\n",
        "print(train_data.info())\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"The percentage of null data in the train dataset:\")\n",
        "print(train_data.isnull().sum() / train_data.shape[0] * 100)\n",
        "\n",
        "cat_col = list(train_data.select_dtypes(['object']).columns)\n",
        "cat_col.remove('Date received')\n",
        "cat_col.remove('Date sent to company')\n",
        "cat_col.remove('Consumer disputed?')\n",
        "\n",
        "for col in cat_col:\n",
        "    print(col, ': train:', train_data[col].nunique(), ' test:', test_data[col].nunique())\n",
        "\n",
        "train_copy = train_data.copy()\n",
        "test_copy = test_data.copy()\n",
        "train_data = train_data.set_index('Complaint ID')\n",
        "test_data = test_data.set_index('Complaint ID')\n",
        "\n",
        "for col in test_data.columns:\n",
        "    varname = col.replace('-', '_').replace('?', '').replace(\" \", '_') + '_isNan'\n",
        "    train_data[varname] = np.where(pd.isnull(train_data[col]), 1, 0)\n",
        "    test_data[varname] = np.where(pd.isnull(test_data[col]), 1, 0)\n",
        "\n",
        "train_data['Date received'] = pd.to_datetime(train_data['Date received'], infer_datetime_format=True)\n",
        "test_data['Date received'] = pd.to_datetime(test_data['Date received'], infer_datetime_format=True)\n",
        "train_data['Date sent to company'] = pd.to_datetime(train_data['Date sent to company'], infer_datetime_format=True)\n",
        "test_data['Date sent to company'] = pd.to_datetime(test_data['Date sent to company'], infer_datetime_format=True)\n",
        "\n",
        "def fe_date(df, column, arg_list):\n",
        "    for arg in arg_list:\n",
        "        df[column + '_' + arg] = df[column].dt.__getattribute__(arg)\n",
        "\n",
        "def fe_date_diff(df, arg_list):\n",
        "    for i, arg_pair in enumerate(arg_list):\n",
        "        df['date_diff_' + str(i)] = (df[arg_pair[1]] - df[arg_pair[0]]).dt.days\n",
        "\n",
        "fe_date(train_data, 'Date received', ['day', 'month', 'year'])\n",
        "fe_date(test_data, 'Date received', ['day', 'month', 'year'])\n",
        "fe_date(train_data, 'Date sent to company', ['day', 'month','year'])\n",
        "fe_date(test_data, 'Date sent to company', ['day', 'month', 'year'])\n",
        "\n",
        "fe_date_diff(train_data, [['Date received', 'Date sent to company']])\n",
        "fe_date_diff(test_data, [['Date received', 'Date sent to company']])\n",
        "\n",
        "lab_enc = ['Product', 'Sub-product', 'Issue', 'Sub-issue', 'Company public response', 'Company', 'State', 'Tags',\n",
        "           'Consumer consent provided?', 'Submitted via', 'Company response to consumer', 'Timely response?']\n",
        "lab_enc_dict = {}\n",
        "\n",
        "for col in lab_enc:\n",
        "    lab_enc_dict[col] = {}\n",
        "    for x, y in enumerate(train_data[col].unique()):\n",
        "        lab_enc_dict[col][y] = x\n",
        "\n",
        "    train_data[col] = train_data[col].map(lab_enc_dict[col])\n",
        "    test_data[col] = train_data[col].map(lab_enc_dict[col])\n",
        "\n",
        "train_data['ZIP code'] = pd.to_numeric(train_data['ZIP code'].str.slice(0, 3), errors='coerce')\n",
        "test_data['ZIP code'] = pd.to_numeric(test_data['ZIP code'].str.slice(0, 3), errors='coerce')\n",
        "\n",
        "\n",
        "def static_clm_creation(df, column, value):\n",
        "    df[column] = value\n",
        "\n",
        "\n",
        "def fe_encoding(df_train, df_test, column, encoding_type):\n",
        "    if encoding_type == 'ohe':\n",
        "        ohe = OneHotEncoder(cols=[column])\n",
        "        df_train = ohe.fit_transform(df_train)\n",
        "        df_train = df_train.drop(column + '_1', axis=1)\n",
        "\n",
        "        df_test = ohe.transform(df_test)\n",
        "        df_test = df_test.drop(column + '_1', axis=1)\n",
        "        return df_train, df_test\n",
        "\n",
        "    if encoding_type == 'oe':\n",
        "        oe = OrdinalEncoder(cols=[column])\n",
        "        df_train = oe.fit_transform(df_train)\n",
        "\n",
        "        df_test = oe.transform(df_test)\n",
        "        return df_train, df_test\n",
        "\n",
        "    if encoding_type == 'be':\n",
        "        oe = BinaryEncoder(cols=[column])\n",
        "        df_train = oe.fit_transform(df_train)\n",
        "\n",
        "        df_test = oe.transform(df_test)\n",
        "        return df_train, df_test\n",
        "\n",
        "\n",
        "train_data_final = train_data.drop(['Date received', 'Consumer complaint narrative', 'Date sent to company'], axis=1)\n",
        "test_data_final = test_data.drop(['Date received', 'Consumer complaint narrative', 'Date sent to company'], axis=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine the train and test datasets\n",
        "combined_data = pd.concat([train_data_final, test_data_final], axis=0)\n",
        "\n",
        "# Create a SimpleImputer with the most frequent strategy\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Fit and transform the combined dataset\n",
        "combined_data_imputed = pd.DataFrame(imputer.fit_transform(combined_data), columns=combined_data.columns)\n",
        "\n",
        "# Split the combined dataset back into train and test datasets\n",
        "train_data_final = combined_data_imputed.iloc[:train_data_final.shape[0]]\n",
        "test_data_final = combined_data_imputed.iloc[train_data_final.shape[0]:]\n",
        "\n",
        "# Convert the target variable to numeric\n",
        "train_data_final['Consumer disputed?'] = train_data_final['Consumer disputed?'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "# Separate X and y\n",
        "y = train_data_final['Consumer disputed?']\n",
        "X = train_data_final.drop(['Consumer disputed?'], axis=1)\n",
        "\n",
        "# Splitting into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.63108084 0.63017643 0.62956565 0.62848979 0.63405991]\n",
            "Mean AUC: 0.6306745224009982\n"
          ]
        }
      ],
      "source": [
        "# Model Training\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Cross Validation\n",
        "scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "# Print the cross-validation scores for each fold\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "# Print the mean cross-validation score\n",
        "print(\"Mean AUC:\", scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.64719552 0.65141186 0.64874726 0.65138304 0.6538234 ]\n",
            "Mean AUC: 0.650512215018072\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Define the categorical columns\n",
        "categorical_columns = ['Product', 'Sub-product', 'Issue', 'Sub-issue', 'Company public response', 'Company',\n",
        "                       'State', 'Tags', 'Consumer consent provided?', 'Submitted via',\n",
        "                       'Company response to consumer', 'Timely response?']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "preprocessor = ColumnTransformer([('encoder', OneHotEncoder(handle_unknown='ignore'), categorical_columns)],\n",
        "                                 remainder='passthrough')\n",
        "\n",
        "# Transform the data\n",
        "X_train_encoded = preprocessor.fit_transform(X_train)\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "# Initialize and train XGBoost model\n",
        "xgboost = XGBClassifier()\n",
        "xgboost.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Cross Validation\n",
        "scores1 = cross_val_score(xgboost, X_train_encoded, y_train, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Print the cross-validation scores for each fold\n",
        "print(\"Cross-validation scores:\", scores1)\n",
        "\n",
        "# Print the mean cross-validation score\n",
        "print(\"Mean AUC:\", scores1.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores: [0.64937369 0.65211447 0.65083043 0.6526629  0.65636906]\n",
            "Mean AUC: 0.6522701095811125\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Define the categorical columns\n",
        "categorical_columns = ['Product', 'Sub-product', 'Issue', 'Sub-issue', 'Company public response', 'Company',\n",
        "                       'State', 'Tags', 'Consumer consent provided?', 'Submitted via',\n",
        "                       'Company response to consumer', 'Timely response?']\n",
        "\n",
        "# Apply one-hot encoding to categorical columns\n",
        "preprocessor = ColumnTransformer([('encoder', OneHotEncoder(handle_unknown='ignore'), categorical_columns)],\n",
        "                                 remainder='passthrough')\n",
        "\n",
        "# Transform the data\n",
        "X_train_encoded = preprocessor.fit_transform(X_train)\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "# Initialize and train the LGBMClassifier\n",
        "lgbmodel = LGBMClassifier()\n",
        "lgbmodel.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Cross Validation\n",
        "scores2 = cross_val_score(lgbmodel, X_train_encoded, y_train, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Print the cross-validation scores for each fold\n",
        "print(\"Cross-validation scores:\", scores2)\n",
        "\n",
        "# Print the mean cross-validation score\n",
        "print(\"Mean AUC:\", scores2.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            "{'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 513, 'subsample': 0.7}\n",
            "Train AUC: 0.6908827604592367\n",
            "Test AUC: 0.6552557660369753\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "# Define the hyperparameter space\n",
        "param_dist = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': sp_randint(100, 1000),\n",
        "    'max_depth': sp_randint(3, 10),\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the LGBMClassifier\n",
        "lgbmodel = LGBMClassifier()\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=lgbmodel,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of parameter settings that are sampled\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,  # Use all available CPU cores\n",
        "    cv=5,  # Number of cross-validation folds\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Perform the random search\n",
        "random_search.fit(X_train_encoded, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found:\")\n",
        "print(random_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Perform predictions and evaluation with the best model\n",
        "train_predictions = best_model.predict_proba(X_train_encoded)[:, 1]\n",
        "test_predictions = best_model.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "train_auc = roc_auc_score(y_train, train_predictions)\n",
        "test_auc = roc_auc_score(y_test, test_predictions)\n",
        "\n",
        "print(\"Train AUC:\", train_auc)\n",
        "print(\"Test AUC:\", test_auc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train AUC: 0.6841794108859887\n",
            "Test AUC: 0.6522037004069259\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the test data\n",
        "X_test_encoded = preprocessor.transform(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "train_predictions_xg = xgboost.predict_proba(X_train_encoded)[:, 1]\n",
        "test_predictions_xg = xgboost.predict_proba(X_test_encoded)[:, 1]\n",
        "\n",
        "train_auc_xg = roc_auc_score(y_train, train_predictions_xg)\n",
        "test_auc_xg = roc_auc_score(y_test, test_predictions_xg)\n",
        "\n",
        "print(\"Train AUC:\", train_auc_xg)\n",
        "print(\"Test AUC:\", test_auc_xg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train AUC: 0.9987300411721269\n",
            "Test AUC: 0.530112358167221\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "train_predictions = rf.predict(X_train)\n",
        "test_predictions = rf.predict(X_test)\n",
        "\n",
        "train_auc = roc_auc_score(y_train, train_predictions)\n",
        "test_auc = roc_auc_score(y_test, test_predictions)\n",
        "\n",
        "print(\"Train AUC:\", train_auc)\n",
        "print(\"Test AUC:\", test_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(119606, 2)\n"
          ]
        }
      ],
      "source": [
        "# Update feature names in train and test datasets\n",
        "train_data_final = train_data_final.drop('Consumer disputed?', axis=1, errors='ignore')  # Remove the target variable if it exists\n",
        "test_data_final = test_data_final[train_data_final.columns]  # Keep only the matching columns\n",
        "\n",
        "# Preprocess the test data\n",
        "test_data_final_encoded = preprocessor.transform(test_data_final)\n",
        "\n",
        "# Predict on the test dataset\n",
        "prediction = lgbmodel.predict_proba(test_data_final_encoded)[:, 1]\n",
        "\n",
        "# Create the submission dataframe\n",
        "submission = pd.DataFrame({'Complaint ID': test_copy['Complaint ID'], 'Consumer disputed?': prediction})\n",
        "submission['Consumer disputed?'] = np.where(submission['Consumer disputed?'] > 0.5, 'Yes', 'No')\n",
        "\n",
        "# Export the submission dataframe to a CSV file\n",
        "submission.to_csv('sample_submission.csv', index=False)\n",
        "print(submission.shape)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
